# Posture-Guided Image Synthesis of a Person

This project aims to implement motion transfer from a source video to a target person using PyTorch. The process follows the paper Everybody Dance Now by Chan et al. (ICCV 2019) and includes various stages to progressively understand Generative Adversarial Networks (GANs). The following sections describe the first two implementations: Nearest Neighbor Search and Direct Neural Network.

## 1. Nearest Neighbor Search

The nearest neighbor approach identifies the frame in the dataset with the skeleton closest to the desired skeleton.

### 1.1 Principle

- Input: A skeleton (ske) representing the target posture.
- Output: The image corresponding to the closest skeleton in the dataset.

This method searches through all skeletons in the target video dataset and computes the Euclidean distance between the input skeleton and each skeleton in the dataset. The image associated with the closest skeleton is selected.
Implementation

### 1.2 Implementation

The implementation is handled in the `GenNearest` class:

    - `__init__` Method: Initializes the generator with a VideoSkeleton object containing the dataset.
    - generate Method:
        - Iterates through all skeletons in the dataset.
        - Finds the skeleton with the smallest distance to the input skeleton.
        - Returns the image corresponding to the closest skeleton.

### 1.3 Usage

- Extract skeletons and images from a target video using VideoSkeleton.
- Use the GenNearest class to generate an image from a new skeleton.

### 1.4 Run

```
    python main.py ...
```

## 2. Direct Neural Network

The direct neural network method trains a simple neural network to generate an image from an input skeleton.

### 2.1 Principle

- Input: A skeleton (ske) reduced to 26 features (13 joints in 2D).
- Output: An image generated by the neural network.

The network uses transposed convolutional layers (ConvTranspose2d) to progressively upsample a tensor from a shape of (batch_size, 26, 1, 1) to (batch_size, 3, 128, 128).

### 2.2 Implementation

The implementation is handled in the GenVanillaNN class:

- Training:
    - A VideoSkeletonDataset is prepared with pairs of skeletons and images.
    - The network is trained using a mean squared error (MSE) loss between generated images and target images.
    - Optimizer: Adam with a learning rate of 0.0001.
    - The network is saved to a file after training.
- Generation:
    - Takes a skeleton as input.
    - Produces an image of the target person in the corresponding posture.

### 2.3 Usage

1. Extract skeletons and images from a target video using VideoSkeleton.
2. Initialize the GenVanillaNN class with the dataset.
3. Train the network using the train method.
4. Generate images from new skeletons using the generate method.

### 2.4 Run

```
    python main.py ...
```

## Project Requirements

Using conda create and activate the environment:

```
conda env create -f environment.yml
conda activate deepan
```

Or manually download the requirements:

```
pip install -r requirements.txt
```

We mention that the version of python use for this project is Python 3.10.15.